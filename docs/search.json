[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT326 Blog",
    "section": "",
    "text": "Mini-Project Refection\n\n\n\n\n\n\nreflection\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCourse Reflection\n\n\n\n\n\n\nreflection\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHypothesis Testing\n\n\n\n\n\n\nmini-project\n\n\n\n\n\n\n\n\n\nApr 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Analysis\n\n\n\n\n\n\nmini-project\n\n\n\n\n\n\n\n\n\nApr 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nConfidence Intervals\n\n\n\n\n\n\nmini-project\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nEstimation\n\n\n\n\n\n\nmini-project\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Distribution\n\n\n\n\n\n\nmini-project\n\n\n\n\n\n\n\n\n\nJan 29, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html",
    "href": "posts/03-confidence-intervals/index.html",
    "title": "Confidence Intervals",
    "section": "",
    "text": "The confidence intervals we have discussed in class each have associated assumptions in order for us to use them correctly. But, what exactly happens if one of the assumptions is violated? Why is a violated assumption ‘bad’ anyway? In this mini-project, you will investigate what happens to interval width and coverage rate if an assumption is violated for the asymptotic confidence interval for a population proportion.\nThe following project will explore generating confidence intervals of a true proportion over 6 different settings. Having a small, medium, and large \\(n\\), as well as having a true proportion close to 0.5 and far from 0.5.\n\n\n\nlibrary(tidyverse)\n\n\ngenerate_onesamp_cis &lt;- function(n, p, alpha) {\n  \n  ## generate a single sample (one of nsim data sets)\n  x &lt;- rbinom(1, n, p)\n  \n  phat &lt;- x / n\n\n  lb &lt;- phat - qnorm(1 - alpha/2) * sqrt((phat * (1 - phat))/n)\n  ub &lt;- phat + qnorm(1 - alpha/2) * sqrt((phat * (1 - phat))/n)\n  \n  ## put everything into a tibble\n  out_df &lt;- tibble(phat, lb, ub)\n  \n  return(out_df)\n}\n\n# test the function once with random data\ngenerate_onesamp_cis(n = 25, p = 0.5, alpha = 0.1)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.52 0.356 0.684\n\n\n\n\n\n\n## define parameters to use in our function\nn &lt;- 10  # sample size\np &lt;- 0.44    # true proportion\nalpha &lt;- 0.1  # used to construct 90% CI\n\n\\(np \\gt 10 \\rightarrow (10)(0.44) \\gt 10 \\rightarrow 4.4 \\not\\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.56) \\gt 10 \\rightarrow 5.6 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\nmany_ci_df\n\n# A tibble: 5,000 × 3\n    phat       lb    ub\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1   0.5  0.240   0.760\n 2   0.4  0.145   0.655\n 3   0.4  0.145   0.655\n 4   0.3  0.0616  0.538\n 5   0.6  0.345   0.855\n 6   0.2 -0.00806 0.408\n 7   0.3  0.0616  0.538\n 8   0.8  0.592   1.01 \n 9   0.5  0.240   0.760\n10   0.5  0.240   0.760\n# ℹ 4,990 more rows\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df\n\n# A tibble: 5,000 × 5\n    phat       lb    ub ci_width ci_cover_ind\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1   0.5  0.240   0.760    0.520            1\n 2   0.4  0.145   0.655    0.510            1\n 3   0.4  0.145   0.655    0.510            1\n 4   0.3  0.0616  0.538    0.477            1\n 5   0.6  0.345   0.855    0.510            1\n 6   0.2 -0.00806 0.408    0.416            0\n 7   0.3  0.0616  0.538    0.477            1\n 8   0.8  0.592   1.01     0.416            0\n 9   0.5  0.240   0.760    0.520            1\n10   0.5  0.240   0.760    0.520            1\n# ℹ 4,990 more rows\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.486         0.798\n\n\n\n\n\n\nn &lt;- 50  \np &lt;- 0.44    \n\n\\(np \\gt 10 \\rightarrow (50)(0.44) \\gt 10 \\rightarrow 22 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.56) \\gt 10 \\rightarrow 28 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.229         0.885\n\n\n\n\n\n\nn &lt;- 1000 \np &lt;- 0.44    \n\n\\(np \\gt 10 \\rightarrow (1000)(0.44) \\gt 10 \\rightarrow 440 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (1000)(0.56) \\gt 10 \\rightarrow 560 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0516         0.896\n\n\n\n\n\n\nn &lt;- 10 \np &lt;- 0.81   \n\n\\(np \\gt 10 \\rightarrow (10)(0.81) \\gt 10 \\rightarrow 8.1 \\not\\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (10)(0.19) \\gt 10 \\rightarrow 1.9 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000 \n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.356         0.846\n\n\n\n\n\n\nn &lt;- 50\np &lt;- 0.81\n\n\\(np \\gt 10 \\rightarrow (50)(0.81) \\gt 10 \\rightarrow 40.5 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.19) \\gt 10 \\rightarrow 9.5 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.180         0.890\n\n\n\n\n\n\nn &lt;- 1000\np &lt;- 0.81\n\n\\(np \\gt 10 \\rightarrow (1000)(0.81) \\gt 10 \\rightarrow 810 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (1000)(0.19) \\gt 10 \\rightarrow 190 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0408         0.901\n\n\n\n\n\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n\n\\(n = 10\\)\n\\(n = 50\\)\n\\(n = 1000\\)\n\n\n\n\n\\(p = 0.44\\)\nCoverage Rate\n0.799\n0.888\n0.893\n\n\n\\(p = 0.81\\)\nCoverage Rate\n0.840\n0.893\n0.903\n\n\n\n\n\n\n\n\n\n\\(p = 0.44\\)\nAverage Width\n0.488\n0.229\n0.0516\n\n\n\\(p = 0.81\\)\nAverage Width\n0.353\n0.179\n0.0408\n\n\n\n\n\n\nFrom class, we saw that the “large sample assumption” only holds when \\(np \\gt 10\\) and \\(n(1-p) \\gt 10\\). We can see from the work here that for both cases were \\(n\\) is small (\\(n = 10\\)) neither proportion value (\\(p = 0.44, 0.81\\)) meets the condition. This indicates that the intervals produced might not be valid. For the medium \\(n\\) values, \\(n = 50\\), the assumption holds when \\(p = 0.44\\), but fails when \\(p = 0.81\\). For large \\(n\\), \\(n = 1000\\), the assumption is met for both values of \\(p\\), meaning that our intervals are likely valid to estimate confidence intervals.\nThe coverage rates for the \\(n = 1000\\) settings are very close to the ideal 90% level, 0.893 and 0.903, for the \\(p = 0.44\\) and \\(p = 0.81\\) settings respectively. This indicates that the use of the normal approximation for the z-score works well in this case. This is consistent with our findings that the “large sample assumption” holds true for large n. For smaller sample sizes (\\(n = 10\\)), the coverage rates are significantly lower for both \\(p\\) settings, which holds with out findings about the “large sample assumption.” Because the assumption was not satisfied, it makes sense that the coverage rate is much lower than the normal approximation would’ve made. For the medium \\(n\\) settings, \\(p = 0.44\\) satisfied the “large sample assumption”, while \\(p = 0.81\\), though the \\(p = 0.81\\) setting still produced a coverage rate closer to 0.9. I would assume that while the setting didn’t satisfy the assumption, \\(n(1-p) = 9.5\\), which might be close enough to 10 that using the normal approximation will still work relatively well.\nWe can see that average width decreases as the sample size increases. For \\(p = 0.44\\), the width drops from 0.488 (\\(n = 10\\)) to 0.0516 (\\(n = 1000\\)). Similarly, for \\(p = 0.81\\), the width decreases from 0.353 (\\(n = 10\\)) to 0.0408 (\\(n = 1000\\)). This makes sense, as increasing the n value will decrease the value of standard error when calculating the value of the upper and lower bounds because the denominator in \\(\\sqrt{\\frac{\\hat{p}(1 - \\hat{p}}{n}}\\). This will decrease the overall average with of the confidence intervals."
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#loading-packages-and-function-def",
    "href": "posts/03-confidence-intervals/index.html#loading-packages-and-function-def",
    "title": "Confidence Intervals",
    "section": "",
    "text": "library(tidyverse)\n\n\ngenerate_onesamp_cis &lt;- function(n, p, alpha) {\n  \n  ## generate a single sample (one of nsim data sets)\n  x &lt;- rbinom(1, n, p)\n  \n  phat &lt;- x / n\n\n  lb &lt;- phat - qnorm(1 - alpha/2) * sqrt((phat * (1 - phat))/n)\n  ub &lt;- phat + qnorm(1 - alpha/2) * sqrt((phat * (1 - phat))/n)\n  \n  ## put everything into a tibble\n  out_df &lt;- tibble(phat, lb, ub)\n  \n  return(out_df)\n}\n\n# test the function once with random data\ngenerate_onesamp_cis(n = 25, p = 0.5, alpha = 0.1)\n\n# A tibble: 1 × 3\n   phat    lb    ub\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.52 0.356 0.684"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-1-small-n-proportion-close-to-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-1-small-n-proportion-close-to-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "## define parameters to use in our function\nn &lt;- 10  # sample size\np &lt;- 0.44    # true proportion\nalpha &lt;- 0.1  # used to construct 90% CI\n\n\\(np \\gt 10 \\rightarrow (10)(0.44) \\gt 10 \\rightarrow 4.4 \\not\\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.56) \\gt 10 \\rightarrow 5.6 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\nmany_ci_df\n\n# A tibble: 5,000 × 3\n    phat       lb    ub\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1   0.5  0.240   0.760\n 2   0.4  0.145   0.655\n 3   0.4  0.145   0.655\n 4   0.3  0.0616  0.538\n 5   0.6  0.345   0.855\n 6   0.2 -0.00806 0.408\n 7   0.3  0.0616  0.538\n 8   0.8  0.592   1.01 \n 9   0.5  0.240   0.760\n10   0.5  0.240   0.760\n# ℹ 4,990 more rows\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df\n\n# A tibble: 5,000 × 5\n    phat       lb    ub ci_width ci_cover_ind\n   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1   0.5  0.240   0.760    0.520            1\n 2   0.4  0.145   0.655    0.510            1\n 3   0.4  0.145   0.655    0.510            1\n 4   0.3  0.0616  0.538    0.477            1\n 5   0.6  0.345   0.855    0.510            1\n 6   0.2 -0.00806 0.408    0.416            0\n 7   0.3  0.0616  0.538    0.477            1\n 8   0.8  0.592   1.01     0.416            0\n 9   0.5  0.240   0.760    0.520            1\n10   0.5  0.240   0.760    0.520            1\n# ℹ 4,990 more rows\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.486         0.798"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-2-medium-n-proportion-close-to-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-2-medium-n-proportion-close-to-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "n &lt;- 50  \np &lt;- 0.44    \n\n\\(np \\gt 10 \\rightarrow (50)(0.44) \\gt 10 \\rightarrow 22 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.56) \\gt 10 \\rightarrow 28 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.229         0.885"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-3-large-n-proportion-close-to-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-3-large-n-proportion-close-to-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "n &lt;- 1000 \np &lt;- 0.44    \n\n\\(np \\gt 10 \\rightarrow (1000)(0.44) \\gt 10 \\rightarrow 440 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (1000)(0.56) \\gt 10 \\rightarrow 560 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0516         0.896"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-4-small-n-proportion-far-from-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-4-small-n-proportion-far-from-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "n &lt;- 10 \np &lt;- 0.81   \n\n\\(np \\gt 10 \\rightarrow (10)(0.81) \\gt 10 \\rightarrow 8.1 \\not\\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (10)(0.19) \\gt 10 \\rightarrow 1.9 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000 \n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.356         0.846"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-5-medium-n-proportion-far-from-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-5-medium-n-proportion-far-from-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "n &lt;- 50\np &lt;- 0.81\n\n\\(np \\gt 10 \\rightarrow (50)(0.81) \\gt 10 \\rightarrow 40.5 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (50)(0.19) \\gt 10 \\rightarrow 9.5 \\not\\gt 10\\)\nIn this case, the large sample assumption does not hold.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.180         0.890"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#setting-6-large-n-proportion-far-from-0.5",
    "href": "posts/03-confidence-intervals/index.html#setting-6-large-n-proportion-far-from-0.5",
    "title": "Confidence Intervals",
    "section": "",
    "text": "n &lt;- 1000\np &lt;- 0.81\n\n\\(np \\gt 10 \\rightarrow (1000)(0.81) \\gt 10 \\rightarrow 810 \\gt 10\\)\n\\(n(1-p) \\gt \\rightarrow (1000)(0.19) \\gt 10 \\rightarrow 190 \\gt 10\\)\nIn this case, the large sample assumption holds.\n\nnsim &lt;- 5000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, p = p,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(p &gt; lb & p &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1    0.0408         0.901"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#table-of-results",
    "href": "posts/03-confidence-intervals/index.html#table-of-results",
    "title": "Confidence Intervals",
    "section": "",
    "text": "Table of Results\n\n\n\n\n\n\n\n\n\n\n\n\\(n = 10\\)\n\\(n = 50\\)\n\\(n = 1000\\)\n\n\n\n\n\\(p = 0.44\\)\nCoverage Rate\n0.799\n0.888\n0.893\n\n\n\\(p = 0.81\\)\nCoverage Rate\n0.840\n0.893\n0.903\n\n\n\n\n\n\n\n\n\n\\(p = 0.44\\)\nAverage Width\n0.488\n0.229\n0.0516\n\n\n\\(p = 0.81\\)\nAverage Width\n0.353\n0.179\n0.0408"
  },
  {
    "objectID": "posts/03-confidence-intervals/index.html#summary",
    "href": "posts/03-confidence-intervals/index.html#summary",
    "title": "Confidence Intervals",
    "section": "",
    "text": "From class, we saw that the “large sample assumption” only holds when \\(np \\gt 10\\) and \\(n(1-p) \\gt 10\\). We can see from the work here that for both cases were \\(n\\) is small (\\(n = 10\\)) neither proportion value (\\(p = 0.44, 0.81\\)) meets the condition. This indicates that the intervals produced might not be valid. For the medium \\(n\\) values, \\(n = 50\\), the assumption holds when \\(p = 0.44\\), but fails when \\(p = 0.81\\). For large \\(n\\), \\(n = 1000\\), the assumption is met for both values of \\(p\\), meaning that our intervals are likely valid to estimate confidence intervals.\nThe coverage rates for the \\(n = 1000\\) settings are very close to the ideal 90% level, 0.893 and 0.903, for the \\(p = 0.44\\) and \\(p = 0.81\\) settings respectively. This indicates that the use of the normal approximation for the z-score works well in this case. This is consistent with our findings that the “large sample assumption” holds true for large n. For smaller sample sizes (\\(n = 10\\)), the coverage rates are significantly lower for both \\(p\\) settings, which holds with out findings about the “large sample assumption.” Because the assumption was not satisfied, it makes sense that the coverage rate is much lower than the normal approximation would’ve made. For the medium \\(n\\) settings, \\(p = 0.44\\) satisfied the “large sample assumption”, while \\(p = 0.81\\), though the \\(p = 0.81\\) setting still produced a coverage rate closer to 0.9. I would assume that while the setting didn’t satisfy the assumption, \\(n(1-p) = 9.5\\), which might be close enough to 10 that using the normal approximation will still work relatively well.\nWe can see that average width decreases as the sample size increases. For \\(p = 0.44\\), the width drops from 0.488 (\\(n = 10\\)) to 0.0516 (\\(n = 1000\\)). Similarly, for \\(p = 0.81\\), the width decreases from 0.353 (\\(n = 10\\)) to 0.0408 (\\(n = 1000\\)). This makes sense, as increasing the n value will decrease the value of standard error when calculating the value of the upper and lower bounds because the denominator in \\(\\sqrt{\\frac{\\hat{p}(1 - \\hat{p}}{n}}\\). This will decrease the overall average with of the confidence intervals."
  },
  {
    "objectID": "posts/02-estimation/index.html",
    "href": "posts/02-estimation/index.html",
    "title": "Estimation",
    "section": "",
    "text": "For this mini-project, you will write a “meaningful story.” A “meaningful story” is one continuous piece of writing / creative work that uses key words from a list and in which the sentences “make sense and hang together.” That is, the ideas in the story must illustrate that you understand key concepts from Stat 326 in a way that allows you to write “meaningfully” about them.\n\n\nThe St. Lawrence University swim team is travelling to their Liberty League championships next week, but their coach is still trying to figure out how to organize the final relay. Normally, the 400 yard free relay has the top 4 fastest swimmers in the event compete in the A relay, the next 4 in the B, and so on. This year, the 4th and 5th place swimmers have 100 yard free times within one-tenth of each other, and almost identical relay splits as well. The coach has to figure out who is going to go in which relay. Instead of randomly picking one or the other, the coach hears that statistics might be able to help them make a fair decision for both swimmers. Ideally, the swimmer best fit for the relay would go just over 54 seconds, which meant that the coach needed to figure out who was most likely to go that time using results from the rest of the season.\nThe average time of a swimmer’s 100 yard freestyle over the course of a season is a parameter, which is an unknown value that can hopefully give an idea of the swimmer’s performance. Because the coach was out of time, and championships was this week, they needed to use an estimator, a function of sample data that could provide an approximation of average time. Using data from all the 100 freestyles the swimmers competed in over the course of the season, they took a random sample of 5 races and calculated both swimmer’s average split time. This sample statistic served as an estimate of the true parameter.\nThe time of each 100 is a random variable, which means that the coach knows that there will be some variation across times, as no one can go the same time over and over and over again. The coach assumed that each swimmer’s 100 times followed a Normal distribution where times exist around an average value with some variation in them.\nBefore creating an estimator and finding an estimate, the coach has to consider possible bias. In an ideal world, the swimmers could swim at their best and their fastest, every single time they swam. This obviously isn’t accurate, so only taking the meets where one swimmer was rested before the race, and the other was sick, would overestimate and underestimate the times respectively. To reduce the bias in the sample, the coach made sure times were picked randomly to get a better overall view. The coach also knows that there can be variance across samples, so they checked whether increasing the sample size to more than 5 races would reduce variability. In addition, when picking the estimator the coach needs to ensure that is consistent, so that as sample size would increase, the estimate would converge to the true value of the population.\nUsing this, the coach analyzed the likelihood of each swimmer going the ideal time by considering samples of their times throughout the season. Each time, the coach calculated the probability that the average time was below 54 seconds. Even with statistical methods, the competition was close, and both swimmers had a high likelihood of being successful. Still the coach put swimmer 1 into the A relay, and swimmer 2 into the B, with the explanation of “it’s what the math says.” In their respective relays, both swimmers swim great, though swimmer 1 goes slightly faster, and the coach breathes a small sigh of relief that the numbers didn’t fail her this time. There’s always next time though…"
  },
  {
    "objectID": "posts/02-estimation/index.html#the-relay-conundrum",
    "href": "posts/02-estimation/index.html#the-relay-conundrum",
    "title": "Estimation",
    "section": "",
    "text": "The St. Lawrence University swim team is travelling to their Liberty League championships next week, but their coach is still trying to figure out how to organize the final relay. Normally, the 400 yard free relay has the top 4 fastest swimmers in the event compete in the A relay, the next 4 in the B, and so on. This year, the 4th and 5th place swimmers have 100 yard free times within one-tenth of each other, and almost identical relay splits as well. The coach has to figure out who is going to go in which relay. Instead of randomly picking one or the other, the coach hears that statistics might be able to help them make a fair decision for both swimmers. Ideally, the swimmer best fit for the relay would go just over 54 seconds, which meant that the coach needed to figure out who was most likely to go that time using results from the rest of the season.\nThe average time of a swimmer’s 100 yard freestyle over the course of a season is a parameter, which is an unknown value that can hopefully give an idea of the swimmer’s performance. Because the coach was out of time, and championships was this week, they needed to use an estimator, a function of sample data that could provide an approximation of average time. Using data from all the 100 freestyles the swimmers competed in over the course of the season, they took a random sample of 5 races and calculated both swimmer’s average split time. This sample statistic served as an estimate of the true parameter.\nThe time of each 100 is a random variable, which means that the coach knows that there will be some variation across times, as no one can go the same time over and over and over again. The coach assumed that each swimmer’s 100 times followed a Normal distribution where times exist around an average value with some variation in them.\nBefore creating an estimator and finding an estimate, the coach has to consider possible bias. In an ideal world, the swimmers could swim at their best and their fastest, every single time they swam. This obviously isn’t accurate, so only taking the meets where one swimmer was rested before the race, and the other was sick, would overestimate and underestimate the times respectively. To reduce the bias in the sample, the coach made sure times were picked randomly to get a better overall view. The coach also knows that there can be variance across samples, so they checked whether increasing the sample size to more than 5 races would reduce variability. In addition, when picking the estimator the coach needs to ensure that is consistent, so that as sample size would increase, the estimate would converge to the true value of the population.\nUsing this, the coach analyzed the likelihood of each swimmer going the ideal time by considering samples of their times throughout the season. Each time, the coach calculated the probability that the average time was below 54 seconds. Even with statistical methods, the competition was close, and both swimmers had a high likelihood of being successful. Still the coach put swimmer 1 into the A relay, and swimmer 2 into the B, with the explanation of “it’s what the math says.” In their respective relays, both swimmers swim great, though swimmer 1 goes slightly faster, and the coach breathes a small sigh of relief that the numbers didn’t fail her this time. There’s always next time though…"
  }
]